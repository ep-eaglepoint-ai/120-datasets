# Trajectory: Order Service Reliability Fix

## Trajectory (Thinking Process for Refactoring)

### 1. Audit the Original Code (Identify Scaling Problems)

I audited the original `order.service.js`. It suffered from critical anti-patterns that caused production failures:

- **N+1 Query Problem:** `getOrdersWithItems` fetched orders, then looped through _every_ order to fetch items individually. For 50 orders, this triggered 51 database round-trips.
- **Race Conditions:** `createOrder` and `reserveStock` read stock levels and then updated them in separate queries ("Read-Modify-Write"). Under concurrency (100 users), this allowed overselling.
- **Resource Leaks:** `getOrderStats` manually checked out a connection but never released it, leading to connection pool exhaustion and server hangs.
- **Security Vulnerabilities:** `searchOrders` injected the `sortBy` parameter directly into the SQL string, creating a critical SQL injection vector.

### 2. Define a Performance Contract First

I defined the performance and reliability conditions required by the business constraints:

- **Latency:** All endpoints must respond in < 200ms.
- **Concurrency:** 100 concurrent users buying limited stock must result in exactly the correct number of sales (no overselling).
- **Data Integrity:** All database mutations (Order + Item + Stock) must happen within an ACID transaction.
- **Stability:** Admin reports must run sequentially without leaking connections.

### 3. Rework the Data Access Strategy (Efficiency)

Since I was constrained from changing the Database Schema, I reworked the _Data Access Layer_ strategy.
I moved from "Application-Side Joining" (looping in Node.js) to "Database-Side Joining." I utilized `LEFT JOIN` to fetch Orders and Items in a single query. This reduces network overhead by ~98% for large datasets.

### 4. Rebuild Search with Safe Projections

I rebuilt `searchOrders` to prevent SQL Injection while maintaining sort flexibility.
Instead of passing raw user input to `ORDER BY`, I implemented an allowlist strategy (`safeSortBy`). This ensures the query structure remains deterministic and secure.

### 5. Move Logic to the Database (Atomic Updates)

I moved the stock validation logic from the Application Server to the Database Server.
Instead of `if (stock > 0) update()`, I used an Atomic SQL update:

```sql
UPDATE products SET stock = stock - ? WHERE id = ? AND stock >= ?
```

This leverages the database's row-level locking to prevent race conditions during flash sales.

## 6. Enforce ACID Transactions

I wrapped the `createOrder` logic in a strict transaction scope:

- `connection.beginTransaction()`
- Insert Order
- Atomic Stock Update (rollback immediately if **0 rows affected**)
- Insert Items
- `connection.commit()` (or `rollback()` on error)

This prevents **ghost orders** (charged but out of stock) and maintains data integrity.

## 7. Eliminate N+1 Queries via In-Memory Aggregation

After switching to the **LEFT JOIN** strategy (Step 3), I implemented an **in-memory aggregation map**.
This takes the flat SQL result set and reconstructs the nested
`Order â†’ Items[]` JSON structure in **O(N)** time within Node.js, completely eliminating the **N+1 query problem**.

## 8. Fix Resource Leaks (Connection Management)

I identified that `getOrderStats` bypassed the pool's auto-release mechanism.

I refactored it to:

- Use `pool.query()` (which handles release automatically), **or**
- Ensure `connection.release()` is called in a `finally` block

This allows the admin dashboard to generate reports indefinitely without crashing.

## 9. Result: Measurable Performance Gains & Predictable Signals

The solution consistently meets all validation scenarios:

- **Latency:** `getOrdersWithItems` dropped
- **Concurrency:** 100 users competing for 50 items results in **exactly 50 sales** and **50 graceful failures**
- **Stability:** Zero connection warnings during high-load reporting
- **Security:** SQL injection attempts are fully neutralized
